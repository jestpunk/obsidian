# Классический ML

>[!question]- В чём заключается метод граничных деревьев?
>Сначала по выборке строим дерево, а затем идём от корня до предсказываемой вершины, пока не окажется так, что у текущей вершины дерева локально нет более близких вершин.

>[!question]- Как строить граничное дерево?
>Выбираем случайный объект за корень. Далее применяем ко всей выборке алгоритм. Если угадали, оставляем всё как есть. Если не угадали, добавляем её в дерево

>[!question]- Что обеспечивает "граничность" дерева?
>Именно то, что точки, предсказываемые верно, не берутся в дерево

- - -

>[!question]- Какие плюсы и минусы у линейных моделей?
>+: Они просты, быстры, интерпретируемы, экстраполируемы, обобщаемы до нелинейных
>-: редко когда линейная зависимость, страдает от выбросов, неоднородности признаков, линейной зависимости признаков

>[!question]- Откуда появляется необходимость в регуляризации?
>Если оставить веса большими, то ошибка на объекте с большим весом будет очень велика, что нежелательно

>[!question]- Какая у регуляризации есть геометрическая интерпретация?
>Она отвечает за "зазор", устойчивость алгоритма к маленьким изменениям. На примере с SVM при увеличении зазора мы как раз минимизируем вес

# DL
## Классический DL

## Computer vision

## NLP

# Математика

## Статистика

Вопрос про то, что линейная модель может давать нам pvalue уверенности 

>[!summary]-  Дивергенция Кульбака-Лейблера
> - **Дивергенция Кульбака-Лейблера** — несимметричная мера удалённости от вероятностного распределения $A$  распределения $B$ (можно понимать как количество потерянной информации об $A$, если мы будем приближать его распределением $B$)
> $$D(A\;||\;B) = \int\limits_X a\log\dfrac{a}{b}d\mu = \mathbb{E}(\log(a(x)) - \log(b(x) | \theta))$$
> - >[!question]- Что такое дивергенция Кульбака-Лейблера?
> >написано сверху
> - >[!question]- симметрична ли дивергенция Кульбака-Лейблера?
>>Нет
> - >[!question]- В чём её физический смысл?
>>Потерянная информация при использовании B вместо A

>[!summary]-  Коэффициенты корелляции
>- **Коэффициент корелляции Пирсона** — нормированная ковариация, описывающая линейность зависимости
>	$$corr(X, Y) = \dfrac{cov(X, Y)}{\sqrt{var(X)var(Y)}} =$$
>	$$= \dfrac{
>	\mathbb{E}((X - \mathbb{E}(X))(Y - \mathbb{E}(Y)))}
>	{\sqrt{
>	\mathbb{E}((X - \mathbb{E}(X))(X - \mathbb{E}(X)))\cdot\mathbb{E}((Y - \mathbb{E}(Y))(Y - \mathbb{E}(Y)))}
>	}$$
>- **Коэффициент корелляции Спирмена** — ранговая корелляция, описывающая монотонную связанность
>	$$corr(X, Y) = \dfrac{\sum\limits_{i=1}^{m}(rank(x_i) - \dfrac{m+1}{2})\cdot(rank(y_i) - \dfrac{m+1}{2})}{\dfrac{1}{12}(m^3-m)}$$
>	
>- >[!question]- Как коэффициент Пирсона соотносится с зависимостью переменных
>	>Независимые переменные некореллированы, наоборот не всегда работает
>- >[!question]- Какие зависимости обнаруживает каждый коэффициент
>	>Пирсон линейные, Спирмен монотонные
>	

>[!question]-  Какие бывают ядра у непараметрических оценок?
>- **Треугольное**:  $\max(\min(1+x, 1-x), 0)$
>-
>- **Квартическое**: $\dfrac{15}{16}(1-x^2)^2\cdot I(|x| < 1)$ 
>- 
>- **Прямоугольное** $\dfrac{1}{2}I(|x| < 1)$
>-
>- **Гауссовское** $\dfrac{1}{\sqrt{2\pi}} \exp(-\dfrac{x^Tx}{2})$
>- 
>- **Епанечникова** $\dfrac{3}{4}(1-x^2)\cdot I(|x|\leq 1)$

- - -

>[!question]- Что такое Bootstrap?
>Приём, позволяющий искусственно увеличивать объём выборки и генерировать её распределение. В нём мы отбираем объекты из нашей выборки так, будто берём их из реального распределения. С повторениями.

>[!question]- Чем Bootstrap помогает в машинном обучении?
>Позволяет не уменьшать размер выборки при разделение на трейн и тест, а просто набирать с повторениями (всё, что не вошло из-за повторов, идёт в тест)

>[!question]- Сколько объектов в среднем будет попадать в тест при Bootstrap (если мы добиваем бутстрепом до размера изначальной выборки)?
>Шанс этого равен шансу ни разу не быть выбранным. $$(1-\dfrac{1}{n})^n \sim e^{-1} \sim 37\%$$

- - -

>[!question]- Что такое MAP оценка?
>Максимум Апостериорной Вероятности это оценка, связанная с ММП, но берущая во внимание априорное распределение величины. Если ММП выглядит так:
>$$ML = \arg\max\limits_{\theta} p(x|\theta)$$
>То MAP берет во внимание некоторое апостериорное распределение параметра $g(\theta)$. Тогда по теореме Байеса функция MAP будет выглядеть как
>$$MAP = \arg\max\limits_{\theta}\dfrac{p(x|\theta) \cdot g(\theta)}{\int p(x|\theta') \cdot g(\theta') d\theta'}$$

>[!question]- Как MAP оценка связана с ММП?
>MAP превращается в ММП при константном апостериорном распределении
 

## Computer science

>[!question]- Какие существуют принципы ООП?
наследование, полиморфизм, инкапсуляция. Есть еще абстракция

>[!question]- Что такое полиморфизм?
Способность методов работать с данными разных типов (и для насекомого, и для самолёта можно запустить команду "лети")

## Линал

>[!question]-  что такое SVD

>[!question]-  почему SVD хорошо обрезать матрицы
>Truncated SVD матрица является ближайшей к изначальной матрице среди матриц своего размера с точки зрения фробениусовой метрики

# Бизнес