# Слупы
Курс Маниты
- - -
### Введение
Пусть $(\Omega, F, P)$ –  *Колмогорова тройка*
*Случайный процесс* – это совокупность случайных величин $(\xi_t,\;t \in T)$, то есть какое-то семейство, в котором есть индексы разных случайных величин. Поток ветра может варьироваться по-разному в разных точках пространства, тогда индексом будут координаты.  Количество машин на перекрестке в разный момент времени варьируется по-разному, тогда индексом будет время, но об этом позже

Очевидно из определения, что для любого случайного процесса конкретная его реализация это случайная величина

>[!summary]- Типы случайных процессов
> 1) $T \subset \mathbb{R}$. Тогда считают, что индекс обозначает *время*
> 2) $T \subset \mathbb{R}^2\;\;(\mathbb{R}^d)$. Тогда  случайный процесс называется *случаным полем*
> 3) $\varphi \rightarrow \xi_{\varphi}$, то есть в качестве индекса у нас некоторая функция. Этот случайный процесс называется *обобщенным случайным полем*

>[!summary]- Примеры случайных процессов
> 1) Просто набор случаных величин (если они норсв, то это будет *выборка*)$$(\xi_t,\;t = \mathbb{N}) = (\xi_1, \xi_2, \dots, \xi_n)$$
> 2) Если $\xi_i$ – норсв, то совокупность следующих случаных величин называют *Бернуллевские случайные величины*$$\xi_i = \begin{cases}1,\;p\\0,\;1-p\end{cases}$$
> 3) *Случайное блуждание* – это когда мы накапливаем последовательность *скачков* $\xi_t$, то есть тоже каких-то случайных величин$$S_0 = 0,\;\;\;S_t = S_{t-1} + \xi_t$$
> 4) *Бернуллевское случайное блуждание* – это когда скачки есть бернуллевские случайные величины. Тогда можно записать $S_t$ через сумму скачков$$S_t^{(b)} = S_{t-1}^{(b)} + \xi_t\;\;\;\Rightarrow\;\;\;S_t^{(b)} = \xi_1 + \xi_2 + \dots + \xi_n$$
- - -

#### Траектория

*Траектория случайного процесса* – это когда мы фиксируем вероятностное пространство, то есть факторы, влиящие на случайность, в какой-то точке $\omega$, и смотрим, какие значения принимают случайные величины нашего процесса с течением времени (с изменением индекса).

![[Pasted image 20220906120209.png]]Траектории одних и тех случайных величин при разных зафиксированных $\omega$

Также траекторию иногда называют *реализацией случайного процесса* или *выборочной функцией случайного процесса*

![[Pasted image 20220906120414.png]]Траектория бернуллевского случайного блуждания

- - -

Заметим, что некоторые случайные величины можно легко привести к бернуллевским. Например, если взять $$\xi'_i = \begin{cases}+1,\;\;p\\-1,\;\;1-p\end{cases}$$То простая замена приводит эту с.в. к бернуллевской
$$\xi_i = (\xi'_i + 1) / 2$$
А так как случайное блуждание есть просто сумма скачков, то тот же фокус работает и с блужданиями
$$S_t = 2S_t^{(b)} - t$$
- - -

#### Модель биномиального рынка (Кокс-Росс-Рубинштейн)
Пусть стоимость бумаги в данный момент есть $U_t = U_t(\omega)$. Считаем, что мы не знаем факторы, влияющие на ее цену. Будем пересчитывать стоимость бумаги, добавляя или отбавляя от нее определенное количество процентов $\rho_t$. Пусть также эта величина увеличивается на какое-то количество $u$ и уменьшается на какое-то количество $d$ (оставляем только два варианта для того, чтобы сводить к бернуллевскому блужданию). Тогда$$U_t = U_{t-1}(1 + \rho_{t})$$$$\rho_i = \begin{cases}u>0,\;\;\;\;\;\;\;\;\;\;\;p\\d\in(-1,0),\;\;1-p\end{cases}$$Видим, что наш пересчет имеет мультикликативную природу. А вот если бы была сумма, то можно было бы сводить блуждание к бернуллевскому... Ну так давайте брать логарифм
$$\log U_t = \log U_{t-1} + {\color{goldenrod}\log(1 + \rho_{t-1})}$$Если назовём выделенный логарифм случайной величиной $\eta$, то получаем следующую зависимость для $\eta$
$$\eta_i = \begin{cases}\log(1 + u),\;\;p\\\log(1 + d),\;\;1-p\end{cases}$$И можем переписать изначальную зависимость в другом виде $$U_t = U_0 e^{aS_{t}^{(b)} - r}$$
- - -
### Модель "капитал страховой компании" (Крамер-Лундберг)
У нас есть страховая в компания, в которую непрерывно несут деньги, и значение нашего капитала монотонно возрастает (можем считать, что с угловым коэффициентом $c$). Так происходит до страхового случая, где капитал падает на $X_i$ – значение $i$-ой страховой выплаты.

![[Pasted image 20220906133806.png]]

В классической модели Крамера-Лундберга $\{X_i\}$ – норсв и $X_i \geq 0$
Пусть $N_t$ – последний момент страховой выплаты к какому-то времени
$$N_t = \max(m:\;\tau_m \leq t)$$
$(N_t,\;t\in \mathbb{R})$ – *Пуассоновский случайный процесс*

Тогда капитал до какого-то момента времени записывает явной формулой $$y_t = y_0 + ct - \sum\limits_{j=1}^{N_t}X_j$$
- - -
*Функция среднего* $m_{\xi}(t) = E(\xi_t)$
*Ковариационное функция случайного процесса* $K_{\xi\xi:\;T\times T} \rightarrow \mathbb{R}$
$$K_{\xi\xi}(t,s)\;=\;cov(\xi_t, \xi_s)\;=\;E(\xi_t - E(\xi_t))E(\xi_s - E(\xi_s))$$
*Конечномерное распределение случайного процесса* $(\xi_{t},\;t \in T)$ , отвечающее набору $t_1, t_2, \dots, t_n$ – это распределение вектора $(\xi_{t_1}, \xi_{t_2}, \dots, \xi_{t_n})$

- - - 

Заметим, что мы "знаем" поведение случайного процесса, если знаем, с какой вероятностью его случайные величины лежат в каких-то множествах $B_i$, то есть можем найти вероятность$$P(\xi_{t_1} = B_1,\;\xi_{t_2} = B_2,\;\dots,\xi_{t_n} = B_n\;)$$

![[Pasted image 20220907183826.png]]

*Семейство конечномерных распределений* – совокупность конечномерных распределений, отвечающих всем наборам, то есть $\forall n \in \mathbb{N};\;\forall\{t_1,t_2,\dots,t_n\}$ 

- - -
### Процессы с независимыми приращениями

$(\xi_t,\;t\in T),\;T \subset \mathbb{R}$ – *Процесс с независимыми приращениями*, если $\forall n,\;\forall t_0 < t_1 < t_2 < \dots < t_n$ приращения $$\xi_{t_0},\;\;\xi_{t_1} - \xi_{t_0},\;\;\xi_{t_2} - \xi_{t_1},\;\;\dots,\;\;\xi_{t_n} - \xi_{t_{n-1}}$$
Независимы между собой

>[!summary]- Примеры
> 1) Случайное блуждание $$S_0 \equiv 0,\;\;S_{t+1} = S_t + \eta_{t+1}$$при $\{\eta_i\}$ – норсв является процессов с независимыми приращениями
>
>2) Модель К-Р-Р не является процессом с независимыми приращениями  

&nbsp;

$(\Pi_t, t\in\mathbb{R}_+)$ – *пуассоновский процесс* с интенсивностью $\alpha$, если
1) $\Pi_0 \equiv 0$ (выходит из нуля)
2) $(\Pi_t, t\in\mathbb{R}_+)$ имеет независимые приращения
3) $\forall s < t:\;\Pi_t - \Pi_s \sim Pois(\lambda)$

>[!done]- распределение Пуассона
> $$\Pi \sim Pois(\lambda) \;\Leftrightarrow\; P(\Pi=k) = \frac{\lambda^k}{k!}e^{-\lambda}$$

Также любой пуассонвский процесс можно **эквивалентно** определить через так называемый процесс восстановления

$$\Pi_i = \max(m:\;\varphi_1 + \varphi_2 + \dots + \varphi_m \leq t)$$где $\{\varphi_i\}$ – норсв и $\varphi_i\sim Exp(\alpha)$

>[!done]- Экспоненциальное распределение
>$$\varphi \sim Exp(\alpha)\;\;\Leftrightarrow\;\;P(\varphi \leq x) = 1 - e^{-\alpha x}$$

&nbsp;

![[Pasted image 20220920162201.png]]Пуассоновский случайный процесс как процесс восстановления