1) Узнать у Пимкина, так же ли они определяли градиент
2) Убрать решение проблем из презентации, оставить только проблемы
3) Валидационная выборка
4) Классические алгоритмы

На предыдущей лекции, посвященной терминам машинного обучения, мы выяснили, что процедура машинного обучения невозможна без оптимизации — с помощью неё мы подбираем параметры модели и улучшаем показатели функции ошибки и метрик качества.  

На этом занятии мы распахнём завесу тайны, стоящей за алгоритмами оптимизации, и узнаем про основные подходы, существующие в этом направлении  

### Общая интуиция

**Визуализация**

Прежде всего стоит вспомнить геометрическую интерпретацию параметров модели. Напомним: все параметры модели являются числами, а значит множество этих чисел можно записать в виде вектора.

Двумерный вектор можно изобразить на двумерной плоскости, тогда как трёхмерный возможно проиллюстрировать только в трёхмерном пространстве. Значит, вектор, состоящий из d параметров модели указывает на какое-то место в d-мерном пространстве.  При этом если сопоставить каждой точке этого пространства функцию ошибок, то получится d+1-мерное пространство, в котором мы можем нарисовать график зависимости функции ошибок от параметров модели. Назовём этот график **поверхностью ошибок**

> **Поверхность ошибок** — кривая, показывающая зависимость функции ошибок от параметров модели

В реальности в любой применимой на практике модели содержатся тысячи, миллионы и миллиарды параметров, но для наглядности в рамках этого урока давайте рассмотрим простейшую модель с двумя параметрами — тогда любой набор параметров является точкой на двумерной плоскости, а график поверхности ошибок задаётся в трёхмерном пространстве

![[Pasted image 20250125085607.png]]

### Градиентный спуск

Итак, назад к оптимизации! У нас есть модель с определённым набором параметров, и при данном наборе параметров модель выдаёт определённое качество работы. Возникает закономерный вопрос: можем ли мы улучшить это качество? 

В каком-то смысле задача улучшения работы модели превращается в задачу "спуска" точки на кривой ошибок в самое нижнее значение: это и будет символизировать улучшение работы модели, то есть её успешное обучение!

Теперь, когда мы поняли основную суть методов оптимизации, пришло время изучить, пожалуй, главный алгоритм оптимизации в машинном обучении — градиентный спуск. Именно на его идее основаны все современные алгоритмы, применяющиеся в реальных задачах
#### Quick recap

Перед тем как вдаваться в подробности, давайте вспомним необходимый теоретический минимум. Градиентом функции, зависящей от нескольких переменных, называют вектор, состоящий из производных этой функции по каждой из переменных

> **Градиент** $\nabla f(x_1, x_2, \dots, x_n)$ функции $f(x_1, x_2, \dots, x_n)$  — это вектор частных производных этой функции
> $$\nabla f(x_1,x_2,\dots, x_n) = (f'|_{x_1},\;f'|_{x_2},\;\dots\;f'|_{x_n})$$
>**Пример**
>Найдём градиент $f(x,y,z) = 5x^2 + 3xy - 12z^5$
>Для этого найдём частные производные этой функции по каждой из переменных
>1) $f(x,y,z)|_{x} = 10x + 3y$
>2) $f(x,y,z)|_{y} = 3x$
>3) $f(x,y,z)|_{z} = 60z^4$
>Значит для любой точки (x,y,z) градиент выглядит следующим образом:
>$$\nabla f(x,y,z) = (10x+3y,\;3x,\;60z^4)$$
Иногда градиент функции обозначают через $\nabla f$ , иногда через $grad\;f$ — это эквивалентные записи

У градиента функции есть одно великолепное и полезное для нас свойство: в каждой конкретной точке пространства градиент функции указывает на направление её наибольшего роста. То есть если мы находимся в точке, в которой график находится под наклоном, и в этой точке градиент равен (3,5,1), то именно в направлении этого вектора происходит наискорейший подъем в направлении этого наклона! 

#### Алгоритм

Посчитав градиент функции мы тут же выясняем, куда двигаться для наискорейшего *увеличения* функции. Есть одно "но":  в ходе обучения модели мы имеем дело с функцией ошибок, и нам наоборот хотелось бы её *уменьшить*. Как вы могли догадаться, для этого идут в направлении, обратном направлению градиента (его также называют антиградиентом)

> **Антиградиент** — вектор, обратный градиенту

При этом важно помнить, что градиент (и антиградиент соответственно) сообщает нам локальную информацию, основанную на вычислениях всего в одной заданной точке! Да, мы знаем направления наискорейшего спуска и подъёма, но выбираем их глядя на локальную область текущей точки и не используем информацию о форме графика в целом. 

Поэтому безоговорочно доверять градиенту нельзя, и вдоль направления, указанного градиентом, лучше пройти совсем чуть-чуть, а дальше посчитать градиент уже в новой точке, чтобы продолжить свою траекторию уже на основе новых данных. В этом и состоит суть метода градиентного спуска — начиная с какого-то стартового положения мы каждый раз считаем градиент в текущей точки, немного сдвигаемся в сторону антиградиента (уменьшая значения функции, производя *спуск*) и повторяем эту процедуру дальше

*иллюстрация с базовым градиентным спуском*

При этом критически важно, с какой скоростью мы будем двигаться в сторону антиградиента. Давайте обозначим темп движения через $\alpha$. Эта величина называется **темпом обучения** (learning rate / lr) и она может существенно поменять свойства градиентного спуска. 
- При высоком темпе обучения мы идём большими шагами, из-за чего оптимизация может быть некачественной (направление, что казалось самым правильным в одной точке, оказалось совсем неверным в точке пососедству из-за специфической формы кривой)
- При низком темпе обучения мы всегда идём по чуть-чуть. Из-за этого мы чаще корректируем направление движения и реже промахиваемся мимо верного направления, но движемся к правильному ответу медленно

*иллюстрация с разными LR*

Алгоритм градиентного спуска состоит из следующих шагов:

1. Выбрать начальную точку $x_0$ и темп обучения $\alpha$.
    
2. Вычислить градиент функции $f(x)$ в точке $x_0$: $\nabla f(x_0)$.
    
3. Сделать шаг в направлении, противоположном градиенту: $x_{n+1} = x_n - \alpha \nabla f(x_n)$
    
4. Повторять шаги 2 и 3 до достижения точки минимума.

#### **Стохастический градиентный спуск**

Стохастический градиентный спуск (Stochastic gradient descend / SGD) является модификацией классического градиентного спуска. В SGD вместо вычисления градиента на всей выборке данных используется случайная подвыборка. Это позволяет заметно ускорить сходимость алгоритма.

Однако стохастический градиентный спуск имеет и недостатки. В частности, есть риск, что вся подвыборка, по которой производится SGD, будет состоять из странных элементов, не похожих на остальной датасет. В этом случае антиградиент подвыборки будет отличаться от антиградиента всех элементов, и параметры изменятся в не самую оптимальную сторону.

#### **Проблемы градиентного спуска**

#### Недифференцируемость
Строго говоря, чтобы применение градиентного спуска имело смысл, мы должны уметь брать градиент функции. Это означает, что у функции должны быть корректно определены все частные производные, и этого нам, вообще-то, никто не обещал.

Давайте вспомним, что мы оптимизируем не абы какую функцию, а функцию ошибок нашей модели, которую мы можем выбирать сами. Хорошая новость: идея взятия производной из функции ошибки настолько понравилась исследователям, что подавляющее большинство функций ошибки корректно дифференцируется и вероятно вам никогда не придётся иметь дело с проблемой недифференцируемости.

#### Локальные минимумы
Мы знаем, что все точки локального минимума имеют нулевые частные производные, и на каждой из этих точек алгоритм градиентного спуска завершит работу (потому что прибавление нулевого градиента никак не влияет на ответ). Но далеко не каждая из этих точек даёт желаемое качество работы модели!

*Иллюстрация локального  и глобального минимума*

Получается, что если в ходе алгоритма градиентного спуска мы попадём в какой-то из локальных минимумов, алгоритм завершит свою работу и выдаст плохое качество! С точки зрения обучения это значит, что модель нашла опредённые параметры, при которых её качество может быть плохим, но любое небольшое изменение параметров делает качество еще хуже.

Чтобы решить эту проблему, можно использовать сразу несколько приёмов. 
Во-первых полезно запускать градиентный спуск из нескольких точек. Даже если несколько запусков застрянут в локальных минмумах, какие-то наверняка дойдут до глобального минимума

*иллюстрация нескольких запусков*

Во-вторых не стоит сразу выбирать очень низкий темп обучения. Если темп обучения достаточно велик, есть шанс перескочить локальный минимум и избежать проблемы. На практике часто поступают хитрее и задают расписание темпа обучения (так называемое шедулирование). Оно указывает, какой темп обучения будет использован на каждой из итераций обучения. Как правило сначала ставят высокий темп обучения, чтобы модель грубыми и смелыми шагами пришла в область глобального минимума, а затем постепенно уменьшают темп обучения, чтобы более точно прийти к оптимальному значению.

В-третьих, существуют модификации градиентного спуска, призванные решать проблему локальных минимумов. Например, ряд оптимизаторов имитирует у точки, спускающейся по графику, инерцию. Точка с инерцией имеет все шансы перескочить через локальный минимум даже с небольшим темпом обучения. Однако о продвинутых алгоритмах оптимизации мы поговорим когда-нибудь потом)

Сегодня ты познакомился с оптимизацией в машинном обучении. Красивая идея перейти от непонятной задачи "сделать модель лучше" к наглядному спуску точки по графику позволила нам придумать целый ряд методов. А благодаря полезным свойствам градиента функции мы придумали градиентный спуск — мощный и важный алгоритм оптимизации в ML

## Разнообразие выборок

### Обучающая и тестовая выборки

Как говорилось на прошлом занятии, процесс машинного обучения включает в себя сбор ответов модели на все данные из датасета. Однако в машинном обучении всегда есть шанс, что модель настолько хорошо оптимизирует ответы на конкретном датасете, что начнёт хуже решать поставленную задачу. 

Казалось бы, разве бывает слишком хорошее решение задачи? Оказывается, что бывает. Происходит это потому что в какой-то момент для достижения еще лучшего качества модели становится нужно не решать задачу честно, а подстроиться под текущий датасет. Из-за этого падает качество на любых новых данных (а мы ведь планируем давать модели новые данные для получения ответов!). Это называется **переобучением** модели

> **Переобучение** — ситуация, при которой модель слишком хорошо изучила особенности датасета. При переобучении модель выдаёт отличное качество на датасете, но плохое на новых, ранее непросмотренных данных

> **Недообучение** — ситуация, при которой модель слишком плохо изучила особенности датасета и должна обучиться ещё

Чтобы избежать переобучения, нам нужно сымитировать для модели получение новых данных. Для этого исходный датасет разбивается на две выборки: обучающую и тестовую. Обучающая выборка выполняет привычную нам задачу: на ней модель производит обучение. При этом тестовая выборка не принимает никакого участия в обучении, а значит на ней мы поймём, насколько модель готова к получению новых, раннее невиданных, данных.

> **Обучающая выборка** — это набор данных, который используется для обучения модели. Модель обучается на основе этой выборки, чтобы научиться распознавать закономерности и делать предсказания.

> **Тестовая выборка** — это отдельный набор данных, который не используется в процессе обучения. Он предназначен для оценки производительности модели после её обучения. Использование тестовой выборки позволяет получить объективную оценку точности модели и избежать переобучения.

Обучающая выборка содержит данные, на которых модель учится делать предсказания, а тестовая выборка используется для проверки этих предсказаний. Это разделение помогает определить, насколько хорошо модель обобщает полученные знания на новые, ранее не встречавшиеся данные.

### Гиперпараметры

До сих пор под "параметром" мы понимали параметры модели, которые настраиваются с помощью метода оптимизации (например, градиентного спуска). Однако существуют также параметры другого вида. Их напрямую обучать с помощью оптимизации мы либо не можем, либо не хотим. Например, не очень понятно, как именно обучать *темп обучения* в градиентном спуске. Да, это настраиваемый параметр и от него зависит итоговый результат, но он не имеет ничего общего с параметрами модели. Такие параметры называются *гиперпараметрами*. 

Гиперпараметры — это параметры, которые задаются перед началом процесса обучения и влияют на саму структуру и поведение модели. Выбор гиперпараметров может существенно повлиять на производительность модели и её способность к обобщению.

> Гиперпараметр — настраиваемый параметр всей работы алгоритма

Настройка гиперпараметров — это важный этап в разработке модели машинного обучения. Она включает в себя выбор оптимальных значений гиперпараметров, которые обеспечивают наилучшую производительность модели на обучающей и тестовой выборках.

### Валидационная выборка

...

## Табличные данные

### Пояснение про таблицы

### Типы признаков

### Отбор признаков