На предыдущей лекции, посвященной терминам машинного обучения, мы выяснили, что процедура машинного обучения невозможна без оптимизации — с помощью неё мы подбираем параметры модели и улучшаем показатели функции ошибки и метрик качества.  

На этом занятии мы распахнём завесу тайны, стоящей за алгоритмами оптимизации, и узнаем про основные подходы, существующие в этом направлении  

### Общая интуиция

**Визуализация**

Прежде всего стоит вспомнить геометрическую интерпретацию параметров модели. Напомним: все параметры модели являются числами, а значит множество этих чисел можно записать в виде вектора.

Двумерный вектор можно изобразить на двумерной плоскости, тогда как трёхмерный возможно проиллюстрировать только в трёхмерном пространстве. Значит, вектор, состоящий из d параметров модели указывает на какое-то место в d-мерном пространстве.  При этом если сопоставить каждой точке этого пространства функцию ошибок, то получится d+1-мерное пространство, в котором мы можем нарисовать график зависимости функции ошибок от параметров модели. Назовём этот график **поверхностью ошибок**

> **Поверхность ошибок** — кривая, показывающая зависимость функции ошибок от параметров модели

В реальности в любой применимой на практике модели содержатся тысячи, миллионы и миллиарды параметров, но для наглядности в рамках этого урока давайте рассмотрим простейшую модель с двумя параметрами — тогда любой набор параметров является точкой на двумерной плоскости, а график поверхности ошибок задаётся в трёхмерном пространстве

*иллюстрация*

### Простейшие алгоритмы оптимизации

Итак, назад к оптимизации! У нас есть модель с определённым набором параметров, и при данном наборе параметров модель выдаёт определённое качество работы. Возникает закономерный вопрос: можем ли мы улучшить это качество? 

В каком-то смысле задача улучшения работы модели превращается в задачу "спуска" точки на кривой в самое нижнее значение: это и будет символизировать улучшение работы модели, то есть её успешное обучение!

*иллюстрация а-ля "плохое качество модели, хорошее качество модели"*

#### Покоординатный спуск

...
#### Метод Ньютона

...
### Градиентный спуск

Теперь, когда мы поняли основную суть методов оптимизации, пришло время изучить, пожалуй, главный алгоритм оптимизации в машинном обучении — градиентный спуск. Именно на его идее основаны все современные алгоритмы, применяющиеся в реальных задачах
#### Quick recap

Перед тем как вдаваться в подробности, давайте вспомним необходимый теоретический минимум. Градиентом функции, зависящей от нескольких переменных, называют вектор, состоящий из производных этой функции по каждой из переменных

> **Градиент** $\nabla f(x_1, x_2, \dots, x_n)$ функции $f(x_1, x_2, \dots, x_n)$  — это вектор частных производных этой функции
> $$\nabla f(x_1,x_2,\dots, x_n) = (f'|_{x_1},\;f'|_{x_2},\;\dots\;f'|_{x_n})$$
>**Пример**
>Найдём градиент $f(x,y,z) = 5x^2 + 3xy - 12z^5$
>Для этого найдём частные производные этой функции по каждой из переменных
>1) $f(x,y,z)|_{x} = 10x + 3y$
>2) $f(x,y,z)|_{y} = 3x$
>3) $f(x,y,z)|_{z} = 60z^4$
>Значит для любой точки (x,y,z) градиент выглядит следующим образом:
>$$\nabla f(x,y,z) = (10x+3y,\;3x,\;60z^4)$$
Иногда градиент функции обозначают через $\nabla f$ , иногда через $grad\;f$ — это эквивалентные записи

У градиента функции есть одно великолепное и полезное для нас свойство: в каждой конкретной точке пространства градиент функции указывает на направление её наибольшего роста. То есть если мы находимся в точке, в которой график находится под наклоном, и в этой точке градиент равен (3,5,1), то именно в направлении этого вектора происходит наискорейший подъем в направлении этого наклона! 

#### Алгоритм

Посчитав градиент функции мы тут же выясняем, куда двигаться для наискорейшего *увеличения* функции. Есть одно "но":  в ходе обучения модели мы имеем дело с функцией ошибок, и нам наоборот хотелось бы её *уменьшить*. Как вы могли догадаться, для этого идут в направлении, обратном направлению градиента (его также называют антиградиентом)

> **Антиградиент** — вектор, обратный градиенту

При этом важно помнить, что градиент (и антиградиент соответственно) сообщает нам локальную информацию, основанную на вычислениях всего в одной заданной точке! Да, мы знаем направления наискорейшего спуска и подъёма, но выбираем их глядя на локальную область текущей точки и не используем информацию о форме графика в целом. 

Поэтому безоговорочно доверять градиенту нельзя, и вдоль направления, указанного градиентом, лучше пройти совсем чуть-чуть, а дальше посчитать градиент уже в новой точке, чтобы продолжить свою траекторию уже на основе новых данных. В этом и состоит суть метода градиентного спуска — начиная с какого-то стартового положения мы каждый раз считаем градиент в текущей точки, немного сдвигаемся в сторону антиградиента (уменьшая значения функции, производя *спуск*) и повторяем эту процедуру дальше

*иллюстрация с базовым градиентным спуском*

При этом критически важно, с какой скоростью мы будем двигаться в сторону антиградиента. Давайте обозначим темп движения через $\alpha$. Эта величина называется **темпом обучения** (learning rate / lr) и она может существенно поменять свойства градиентного спуска. 
- При высоком темпе обучения мы идём большими шагами, из-за чего оптимизация может быть некачественной (направление, что казалось самым правильным в одной точке, оказалось совсем неверным в точке пососедству из-за специфической формы кривой)
- При низком темпе обучения мы всегда идём по чуть-чуть. Из-за этого мы чаще корректируем направление движения и реже промахиваемся мимо верного направления, но 

*иллюстрация с разными LR*

Алгоритм градиентного спуска состоит из следующих шагов:

1. Выбрать начальную точку $x_0$ и темп обучения $\alpha$.
    
2. Вычислить градиент функции $f(x)$ в точке $x_0$: $\nabla f(x_0)$.
    
3. Сделать шаг в направлении, противоположном градиенту: $x_{n+1} = x_n - \alpha \nabla f(x_n)$
    
4. Повторять шаги 2 и 3 до достижения точки минимума.

#### **Стохастический градиентный спуск**

Стохастический градиентный спуск (Stochastic gradient descend / SGD) является модификацией классического градиентного спуска. В SGD вместо вычисления градиента на всей выборке данных используется только одна случайно выбранная точка. Это позволяет ускорить сходимость алгоритма и уменьшить риск переобучения модели.

Однако стохастический градиентный спуск имеет и недостатки, такие как более высокая дисперсия оценок градиента и возможность расхождения алгоритма при некоторых условиях. Для обеспечения сходимости SGD необходимо выбирать размер шага с учётом свойств функции и характеристик данных.

В этой главе мы рассмотрели основные аспекты градиентного спуска, включая его геометрическую интерпретацию, алгоритм, скорость сходимости и стохастическую версию. Градиентный спуск остаётся одним из основных инструментов оптимизации в машинном обучении и других областях.

#### **Проблемы градиентного спуска**



## Разнообразие выборок

### Обучающая и тестовая выборки

В машинном обучении выборка данных играет ключевую роль в процессе обучения модели. Выборка делится на две основные категории: обучающую и тестовую.

> **Обучающая выборка** — это набор данных, который используется для обучения модели. Модель обучается на основе этой выборки, чтобы научиться распознавать закономерности и делать предсказания.

> **Тестовая выборка** — это отдельный набор данных, который не используется в процессе обучения. Он предназначен для оценки производительности модели после её обучения. Использование тестовой выборки позволяет получить объективную оценку точности модели и избежать переобучения.

Обучающая выборка содержит данные, на которых модель учится делать предсказания, а тестовая выборка используется для проверки этих предсказаний. Это разделение помогает определить, насколько хорошо модель обобщает полученные знания на новые, ранее не встречавшиеся данные.

### Гиперпараметры

Гиперпараметры — это параметры, которые задаются перед началом процесса обучения и влияют на саму структуру и поведение модели. Например, в градиентном спуске Они не изменяются в процессе обучения, в отличие от весов модели, которые обновляются на основе обучающих данных. Выбор гиперпараметров может существенно повлиять на производительность модели и её способность к обобщению.

> Гиперпараметр — настраиваемый параметр всей работы алгоритма

Настройка гиперпараметров — это важный этап в разработке модели машинного обучения. Она включает в себя выбор оптимальных значений гиперпараметров, которые обеспечивают наилучшую производительность модели на обучающей и тестовой выборках. Существует несколько методов настройки гиперпараметров, включая поиск по сетке (grid search) и случайный поиск (random search).

### Валидационная выборка

Валидационная выборка — это дополнительный набор данных, используемый для тонкой настройки гиперпараметров модели. В отличие от тестовой выборки, валидационная выборка используется в процессе настройки гиперпараметров.

Модель обучается на обучающей выборке, затем производительность проверяется на валидационной выборке. Если производительность на валидационной выборке ухудшается, это может указывать на переобучение модели. В этом случае можно попробовать изменить гиперпараметры или добавить регуляризацию.

![](/api/attachments.redirect?id=3f6b1558-0037-4bfa-9032-d58ae614706c)

Использование валидационной выборки помогает выбрать оптимальные гиперпараметры и предотвратить переобучение. Это особенно полезно при работе с большими наборами данных, где тестирование на тестовой выборке может быть затруднено из-за вычислительных ограничений.

Таким образом, обучающая, тестовая и валидационная выборки являются важными инструментами в арсенале машинного обучения. Понимание их роли и правильное использование позволяет создавать более точные и надёжные модели, способные эффективно работать с новыми данными.

## Табличные данные

### Пояснение про таблицы

### Типы признаков

### Отбор признаков